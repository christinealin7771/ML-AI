{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Index  Sentiment                                               Text\n",
      "0      0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1      1          0  is upset that he can't update his Facebook by ...\n",
      "2      2          0  @Kenichan I dived many times for the ball. Man...\n",
      "3      3          0    my whole body feels itchy and like its on fire \n",
      "4      4          0  @nationwideclass no, it's not behaving at all....\n",
      "   Index  Sentiment                                               Text\n",
      "0      0          1  @stellargirl I loooooooovvvvvveee my Kindle2. ...\n",
      "1      1          1  Reading my kindle2...  Love it... Lee childs i...\n",
      "2      2          1  Ok, first assesment of the #kindle2 ...it fuck...\n",
      "3      3          1  @kenburbary You'll love your Kindle2. I've had...\n",
      "4      4          1  @mikefish  Fair enough. But i have the Kindle2...\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(array([], dtype=int64), array([], dtype=int64))\n",
      "(1048575, 3)\n",
      "(359, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(train.head())\n",
    "print(test.head())\n",
    "\n",
    "print(np.where(pd.isnull(train)))\n",
    "print(np.where(pd.isnull(test)))\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Index  Sentiment                                               Text\n",
      "0      0          0  @switchfoot http://twitpic.com/2y1zl - awww, t...\n",
      "1      1          0  is upset that he can't update his facebook by ...\n",
      "2      2          0  @kenichan i dived many times for the ball. man...\n",
      "3      3          0    my whole body feels itchy and like its on fire \n",
      "4      4          0  @nationwideclass no, it's not behaving at all....\n",
      "   Index  Sentiment                                               Text\n",
      "0      0          1  @stellargirl i loooooooovvvvvveee my kindle2. ...\n",
      "1      1          1  reading my kindle2...  love it... lee childs i...\n",
      "2      2          1  ok, first assesment of the #kindle2 ...it fuck...\n",
      "3      3          1  @kenburbary you'll love your kindle2. i've had...\n",
      "4      4          1  @mikefish  fair enough. but i have the kindle2...\n",
      "   Index  Sentiment                                               Text\n",
      "0      0          0  @switchfoot http://twitpic.com/yzl - awww, tha...\n",
      "1      1          0  is upset that he can't update his facebook by ...\n",
      "2      2          0  @kenichan i dived many times for the ball. man...\n",
      "3      3          0     my whole body feels itchy and like its on fire\n",
      "4      4          0  @nationwideclass no, it's not behaving at all....\n",
      "   Index  Sentiment                                               Text\n",
      "0      0          1  @stellargirl i loooooooovvvvvveee my kindle. n...\n",
      "1      1          1  reading my kindle...  love it... lee childs is...\n",
      "2      2          1  ok, first assesment of the #kindle ...it fucki...\n",
      "3      3          1  @kenburbary you'll love your kindle. i've had ...\n",
      "4      4          1  @mikefish  fair enough. but i have the kindle ...\n",
      "   Index  Sentiment                                               Text\n",
      "0      0          0  @switchfoot   - awww, that's a bummer.  you sh...\n",
      "1      1          0  is upset that he can't update his facebook by ...\n",
      "2      2          0  @kenichan i dived many times for the ball. man...\n",
      "3      3          0     my whole body feels itchy and like its on fire\n",
      "4      4          0  @nationwideclass no, it's not behaving at all....\n",
      "   Index  Sentiment                                               Text\n",
      "0      0          1  @stellargirl i loooooooovvvvvveee my kindle. n...\n",
      "1      1          1  reading my kindle...  love it... lee childs is...\n",
      "2      2          1  ok, first assesment of the #kindle ...it fucki...\n",
      "3      3          1  @kenburbary you'll love your kindle. i've had ...\n",
      "4      4          1  @mikefish  fair enough. but i have the kindle ...\n",
      "   Index  Sentiment                                               Text\n",
      "0      0          0  - awww, that's a bummer.  you shoulda got davi...\n",
      "1      1          0  is upset that he can't update his facebook by ...\n",
      "2      2          0  i dived many times for the ball. managed to sa...\n",
      "3      3          0     my whole body feels itchy and like its on fire\n",
      "4      4          0  no, it's not behaving at all. i'm mad. why am ...\n",
      "   Index  Sentiment                                               Text\n",
      "0      0          1  i loooooooovvvvvveee my kindle. not that the d...\n",
      "1      1          1  reading my kindle...  love it... lee childs is...\n",
      "2      2          1  ok, first assesment of the #kindle ...it fucki...\n",
      "3      3          1  you'll love your kindle. i've had mine for a f...\n",
      "4      4          1  fair enough. but i have the kindle and i think...\n",
      "   Index  Sentiment                                               Text\n",
      "0      0          0  awww  that s a bummer   you shoulda got david ...\n",
      "1      1          0  is upset that he can t update his facebook by ...\n",
      "2      2          0  i dived many times for the ball  managed to sa...\n",
      "3      3          0     my whole body feels itchy and like its on fire\n",
      "4      4          0  no  it s not behaving at all  i m mad  why am ...\n",
      "   Index  Sentiment                                               Text\n",
      "0      0          1  i loooooooovvvvvveee my kindle  not that the d...\n",
      "1      1          1  reading my kindle     love it    lee childs is...\n",
      "2      2          1  ok  first assesment of the  kindle    it fucki...\n",
      "3      3          1  you ll love your kindle  i ve had mine for a f...\n",
      "4      4          1  fair enough  but i have the kindle and i think...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Part 2 - Text Preprocessing\n",
    "\n",
    "'''\n",
    "\n",
    "# 1: lower-casing\n",
    "train['Text'] = train['Text'].str.lower()\n",
    "print(train.head())\n",
    "\n",
    "test['Text'] = test['Text'].str.lower()\n",
    "print(test.head())\n",
    "\n",
    "# 2: remove digital numbers\n",
    "\n",
    "import re #python regular expression library\n",
    "\n",
    "train['Text'] = train['Text'].apply(lambda x: re.sub('[0-9]', '', x).strip())\n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub('[0-9]', '', x).strip())\n",
    "print(train.head())\n",
    "print(test.head())\n",
    "\n",
    "\n",
    "# 3: Remove urls\n",
    "                    \n",
    "train['Text'] = train['Text'].apply(lambda x: re.sub('http\\S+', ' ', x).strip())\n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub('http\\S+', ' ', x).strip())\n",
    "print(train.head())\n",
    "print(test.head())\n",
    "\n",
    "\n",
    "# 4: Remove username\n",
    "\n",
    "train['Text'] = train['Text'].apply(lambda x: re.sub('@[^\\s]+', '', x).strip())\n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub('@[^\\s]+', '', x).strip())\n",
    "print(train.head())\n",
    "print(test.head())\n",
    "\n",
    "\n",
    "\n",
    "# 5: Remove special character and puncation \n",
    "train['Text'] = train['Text'].apply(lambda x: re.sub('[^a-z0-9<>]', ' ', x).strip())\n",
    "test['Text'] = test['Text'].apply(lambda x: re.sub('[^a-z0-9<>]', ' ', x).strip())\n",
    "print(train.head())\n",
    "print(test.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Part 3 - Linguistic Feature Extraction\n",
    "\n",
    "'''\n",
    "\n",
    "# 1. Bag of Words\n",
    "list_of_texts = train['Text'].tolist()\n",
    "print(list_of_texts)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
